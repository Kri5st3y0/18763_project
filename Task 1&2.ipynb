{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "94a7ede7-37be-471a-9641-0e02d76d2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql.functions import col, when, lit, to_date\n",
    "from pyspark.sql.types import IntegerType, StringType, DoubleType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3eef8652-2d1c-43ab-84e3-5d540fb9d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e84d6-671a-419b-a4f0-dc29c70408ba",
   "metadata": {},
   "source": [
    "## Task-I: Build and populate necessary tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "53577646-7039-4a4d-96ab-1e6f1812dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url = \"jdbc:postgresql://localhost:5432/postgres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e40d5c2f-b35a-45ac-a613-89560074f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [16, 17, 18, 19, 20, 21, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3e6a824f-23df-4557-9b81-2bf0004617cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"FIFA/players_15.csv\"\n",
    "df = spark.read.csv(path, header=True, inferSchema=True)\n",
    "df = df.withColumn(\"year\", lit(2015))\n",
    "df = df.withColumn(\"gender\", lit(\"M\"))\n",
    "df.write.jdbc(url=jdbc_url, table=\"public.FIFA\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "21329cd1-b601-4f49-8a33-74937b7402f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    male_path = f\"FIFA/players_{year}.csv\"\n",
    "    male_df = spark.read.csv(male_path, header=True, inferSchema=True)\n",
    "    male_df = male_df.withColumn(\"year\", lit(year + 2000).cast(IntegerType()))\n",
    "    male_df = male_df.withColumn(\"gender\", lit(\"M\"))\n",
    "    male_df.write.jdbc(url=jdbc_url, table=\"public.FIFA\", mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44431404-0d38-4a80-b991-2cf8501b66ac",
   "metadata": {},
   "source": [
    "#### Since there are many 100% empty columns in csv files of female players, we need to deal with missing values before insertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bd3adb70-a0ba-419a-964d-7710a155583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    female_path = f\"FIFA/female_players_{year}.csv\"\n",
    "    female_df = spark.read.csv(female_path, header=True, inferSchema=True)\n",
    "    female_df = female_df.withColumn(\"year\", lit(year).cast(IntegerType()))\n",
    "    female_df = female_df.withColumn(\"gender\", lit(\"F\"))\n",
    "    for column_name in female_df.columns:\n",
    "        male_column_type = df.schema[column_name].dataType\n",
    "        if isinstance(male_column_type, IntegerType):\n",
    "            female_df = female_df.withColumn(column_name, when(col(column_name).isNull(), lit(0)).otherwise(col(column_name).cast(IntegerType())))\n",
    "        elif isinstance(male_column_type, StringType):\n",
    "            female_df = female_df.withColumn(column_name, when(col(column_name).isNull(), lit(\"NA\")).otherwise(col(column_name).cast(StringType())))\n",
    "        elif isinstance(male_column_type, DoubleType):\n",
    "            female_df = female_df.withColumn(column_name, when(col(column_name).isNull(), lit(0.0)).otherwise(col(column_name).cast(DoubleType())))\n",
    "        elif isinstance(male_column_type, DateType):\n",
    "            female_df = female_df.withColumn(column_name, when(col(column_name).isNull(), to_date(lit(\"1970-01-01\"), \"yyyy-MM-dd\")).otherwise(col(column_name).cast(DateType())))\n",
    "            \n",
    "    female_df.write.jdbc(url=jdbc_url, table=\"public.FIFA\", mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac50f41-cebd-4672-a296-a359efe65fe2",
   "metadata": {},
   "source": [
    "#### Read Data back from PostgresDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "69f1a75d-ef2a-438c-bcdd-5449d6c5c31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.jdbc(url=jdbc_url, table=\"public.fifa\")\n",
    "output_path = \"fifa_data.csv\"\n",
    "df.write.csv(output_path, header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456d7889-dc82-412b-8cd3-6cb1042d30ab",
   "metadata": {},
   "source": [
    "## Task-II: Conduct analytics on your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc68af8-f46b-4cac-8fb7-55e19100c8c7",
   "metadata": {},
   "source": [
    "**In Year X, what were the Y clubs that had the highest number of players with contracts ending in year Z (or after)?**  \n",
    "- X is a year between (2015 and 2022, inclusively).  \n",
    "- Y is a positive integer.  \n",
    "- Z is a year that can hold the value of 2023 or a year after it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0604a7ee-14f6-4f34-87b9-6d1e2c0f2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df.filter((df['gender'] == \"M\") & (df['club_name'].isNotNull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "6b8aa6b3-191f-4a73-a114-92ebec24f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_clubs_by_player_contracts(df, year, club_num, end_year):\n",
    "    if year < 2015 or year > 2022:\n",
    "        print(\"Please provide a valid joining year!\")\n",
    "        return\n",
    "    if end_year < 2023:\n",
    "        print(\"Please provide a valid contract ending year after 2023!\")\n",
    "        return\n",
    "    if club_num <= 0:\n",
    "        print(\"Please provide a positive number of clubs!\")\n",
    "        return\n",
    "    \n",
    "    df.createOrReplaceTempView(\"temp\")\n",
    "    query = f\"\"\"\n",
    "        SELECT club_name, COUNT(sofifa_id) AS player_count\n",
    "        FROM temp\n",
    "        WHERE club_contract_valid_until >= {end_year} \n",
    "        AND year = {year}\n",
    "        GROUP BY club_name\n",
    "        ORDER BY player_count DESC\n",
    "        LIMIT {club_num};\"\"\"\n",
    "    top_clubs = spark.sql(query)\n",
    "    top_clubs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "826608d5-d92b-4efc-836f-0d0257db30d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|           club_name|player_count|\n",
      "+--------------------+------------+\n",
      "|Jaguares de Córdo...|          18|\n",
      "|    Rionegro Águilas|          15|\n",
      "|     Deportivo Pasto|          15|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_top_clubs_by_player_contracts(sub_df, 2019, 3, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64875c4e-0c0c-423b-9866-ea28adf565ee",
   "metadata": {},
   "source": [
    "**List the X clubs with the highest (or lowest) average player age for a given year Y.**  \n",
    "- X represents a positive integer, but you should handle a scenario if X is not positive value.\n",
    "- Y represents a year between 2015 and 2022 inclusively.\n",
    "- Provide the user with the ability to choose if they want the highest average age or the lowest average age.\n",
    "- *Make sure to handle this scenario as well: if the user requests 5 clubs with highest averages but there are 3 clubs that share the same count at rank number 5, please include all of them in your output*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1cba4889-ebaa-49de-b362-5c26757536e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clubs_by_average_age(df, club_num, year, highest=True):\n",
    "    if club_num <= 0:\n",
    "        print(\"Please provide a positive number of clubs!\")\n",
    "        return\n",
    "    if year < 2015 or year > 2022:\n",
    "        print(\"Please provide a valid year! 2015 <= year <= 2022\")\n",
    "        return\n",
    "    sub_df = df.filter((df['year'] == year))\n",
    "    sub_df.createOrReplaceTempView(\"temp\")\n",
    "    order = \"DESC\" if highest else \"ASC\"\n",
    "    query_cal_avg = \"\"\"\n",
    "        SELECT club_name, AVG(age) AS average_age\n",
    "        FROM temp\n",
    "        GROUP BY club_name;\"\"\"\n",
    "    sub_df_with_avg = spark.sql(query_cal_avg)\n",
    "\n",
    "    sub_df_with_avg.createOrReplaceTempView(\"temp1\")\n",
    "    group_query = f\"\"\"\n",
    "        SELECT average_age, COUNT(club_name) FROM temp1\n",
    "        GROUP BY average_age\n",
    "        ORDER BY average_age {order}\n",
    "        LIMIT {club_num};\"\"\"\n",
    "    top_values = spark.sql(group_query)\n",
    "    top_values_list = [row['average_age'] for row in top_values.collect()]\n",
    "    \n",
    "    select_query = f\"\"\"\n",
    "        SELECT club_name, average_age FROM temp1\n",
    "        WHERE average_age IN ({','.join(map(str, top_values_list))})\n",
    "        ORDER BY average_age {order};\"\"\"\n",
    "    result = spark.sql(select_query)\n",
    "    result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "510cad0a-c1f4-4cfd-8adc-e2bc2476614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|           club_name|average_age|\n",
      "+--------------------+-----------+\n",
      "|           Fortaleza|       32.6|\n",
      "|            Cruzeiro|       31.6|\n",
      "|Club Athletico Pa...|       31.4|\n",
      "|            Botafogo|       31.4|\n",
      "|Associação Chapec...|       31.4|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_clubs_by_average_age(sub_df, 3, 2020, highest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a2adf481-4bcd-4288-ad40-885806a07d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|           club_name|       average_age|\n",
      "+--------------------+------------------+\n",
      "|    Bolton Wanderers| 20.26086956521739|\n",
      "|             UCD AFC|20.428571428571427|\n",
      "|FC Bayern München II|20.892857142857142|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_clubs_by_average_age(sub_df, 3, 2020, highest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "bb91c35f-9806-454b-88ad-84a692636193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_popular_nationality(df):\n",
    "    df.createOrReplaceTempView(\"temp\")\n",
    "    query1 = \"\"\"\n",
    "        SELECT nationality_name, year, COUNT(sofifa_id) AS count FROM temp\n",
    "        WHERE gender = \"M\"\n",
    "        GROUP BY nationality_name, year;\"\"\"\n",
    "    result = spark.sql(query1)\n",
    "    result.createOrReplaceTempView(\"temp1\")\n",
    "    query2 = \"\"\"\n",
    "        SELECT temp1.year, temp1.nationality_name, temp1.count\n",
    "        FROM temp1 \n",
    "        JOIN (\n",
    "            SELECT year, MAX(count) AS max_count\n",
    "            FROM temp1\n",
    "            GROUP BY year\n",
    "        ) AS max ON temp1.year = max.year AND temp1.count = max.max_count\n",
    "        ORDER BY temp1.year;\"\"\"\n",
    "    result = spark.sql(query2)\n",
    "    result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8ecf0e42-e88f-4d74-81b9-a28a027457f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+-----+\n",
      "|year|nationality_name|count|\n",
      "+----+----------------+-----+\n",
      "|2015|         England| 1627|\n",
      "|2016|         England| 1519|\n",
      "|2017|         England| 1627|\n",
      "|2018|         England| 1633|\n",
      "|2019|         England| 1625|\n",
      "|2020|         England| 1670|\n",
      "|2021|         England| 1685|\n",
      "|2022|         England| 1719|\n",
      "+----+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_most_popular_nationality(sub_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
